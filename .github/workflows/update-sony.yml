name: Auto Update Sony M3U Tokens
permissions:
  contents: write

on:
  schedule:
    - cron: '0 */11 * * *'  # every 11 hours
  workflow_dispatch:

jobs:
  update-sony:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests

      - name: Update sony.m3u tokens
        run: |
          python - <<'PY'
          import re, requests, os
          from datetime import datetime

          API_URL = "https://livetv-cb7.pages.dev/Slivplaylist"
          LOCAL_FILE = "sony.m3u"

          def parse_m3u(content):
              entries = []
              lines = content.splitlines()
              for i, line in enumerate(lines):
                  if line.startswith("#EXTINF"):
                      header = line.strip()
                      if i + 1 < len(lines):
                          url = lines[i + 1].strip()
                          tvg_id = re.search(r'tvg-id="([^"]+)"', header)
                          tvg_name = re.search(r'tvg-name="([^"]+)"', header)
                          raw_name = tvg_name.group(1) if tvg_name else ""
                          norm_name = raw_name.lower().replace(" ", "").replace("-", "").replace("_", "")
                          entries.append({
                              "id": (tvg_id.group(1).lower() if tvg_id else ""),
                              "name": norm_name,
                              "raw_name": raw_name,
                              "header": header,
                              "url": url
                          })
              return entries

          print("🔄 Fetching latest playlist...")
          resp = requests.get(API_URL, timeout=30)
          resp.raise_for_status()
          new_data = resp.text.strip()

          new_entries = parse_m3u(new_data)
          sony_new = [e for e in new_entries if "sony" in e["id"] or "sony" in e["name"]]
          print(f"✅ Found {len(sony_new)} Sony channels in API.")

          if not sony_new:
              print("⚠️ No Sony entries found in API — skipping.")
              exit(0)

          if not os.path.exists(LOCAL_FILE):
              print("⚠️ sony.m3u not found — creating new one.")
              lines = ["#EXTM3U", f"# Created: {datetime.utcnow().isoformat()} UTC", ""]
              for e in sony_new:
                  lines += [e["header"], e["url"]]
              with open(LOCAL_FILE, "w", encoding="utf-8") as f:
                  f.write("\n".join(lines))
              exit(0)

          with open(LOCAL_FILE, "r", encoding="utf-8") as f:
              old_data = f.read()

          old_entries = parse_m3u(old_data)
          updated_lines = ["#EXTM3U", f"# Updated: {datetime.utcnow().isoformat()} UTC", ""]
          updated_count = 0
          added_count = 0

          def find_match(old):
              for new in sony_new:
                  # exact id match OR normalized name contains/equals
                  if (old["id"] and new["id"] and old["id"] == new["id"]):
                      return new
                  if old["name"] and new["name"]:
                      if old["name"] == new["name"]:
                          return new
                      if old["name"] in new["name"] or new["name"] in old["name"]:
                          return new
              return None

          for old in old_entries:
              match = find_match(old)
              if match:
                  # normalize small url differences when comparing
                  if match["url"].strip() != old["url"].strip():
                      updated_count += 1
                      print(f"🔁 Updated: {old['raw_name'] or old['id']}")
                  updated_lines.append(match["header"])
                  updated_lines.append(match["url"])
              else:
                  updated_lines.append(old["header"])
                  updated_lines.append(old["url"])

          # add any new sony entries that weren't present before
          old_names = {o["name"] for o in old_entries}
          for new in sony_new:
              if new["name"] not in old_names:
                  updated_lines.append(new["header"])
                  updated_lines.append(new["url"])
                  added_count += 1
                  print(f"🆕 Added: {new['raw_name'] or new['id']}")

          with open(LOCAL_FILE, "w", encoding="utf-8") as f:
              f.write("\n".join(updated_lines))

          print(f"🎉 sony.m3u updated: {updated_count} updated, {added_count} added.")
          PY

      - name: Commit and push if changed (skip Pages)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add sony.m3u
          if git diff --staged --quiet; then
            echo "✅ No changes to commit"
          else
            git commit -m "🔄 Auto-update Sony M3U tokens ($(date -u)) [skip ci] [skip actions]"
            git push origin HEAD:${{ github.ref }}
            echo "✅ sony.m3u updated and pushed successfully."
          fi
